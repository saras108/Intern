{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target                                           Sentence\n",
       "0      joy  On days when I feel close to my partner and ot...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_csv = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'\n",
    "df = pd.read_csv(\"1-P-3-ISEAR.csv\",header=None)\n",
    "\n",
    "\n",
    "df.columns = ['sn','Target','Sentence']\n",
    "df.drop('sn',inplace=True,axis =1)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = {        \n",
    "    'joy':1,\n",
    "    'sadness':2,\n",
    "    'anger':3,\n",
    "    'fear': 4,\n",
    "    'shame':5,\n",
    "    'disgust':6,\n",
    "    'guilt':0\n",
    "    }\n",
    "\n",
    "def get_key(val):\n",
    "    for key, value in emotion.items():\n",
    "         if val == value:\n",
    "             return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (5956,)\n",
      "shape of test data is (1490,)\n"
     ]
    }
   ],
   "source": [
    "X,y = df['Sentence'].values,df['Target'].values\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=10)\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'guilt', 'fear', ..., 'disgust', 'guilt', 'fear'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "\n",
    "# dd\n",
    "sns.barplot(x=np.array(['joy','sadness','anger','fear','disgust','shame','guilt']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):    \n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s) # Remove all non-word characters \n",
    "    s = re.sub(r\"\\s+\", '', s) # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\d\", '', s) # replace digits with no space\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tockenize(x_train,y_train,x_val,y_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    corpus = Counter(word_list)\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000] # sorting on the basis of most common words\n",
    "    \n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_val:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "\n",
    "   \n",
    "    encoded_train = [emotion[label] for label in y_train]\n",
    "    encoded_test = [emotion[label] for label in y_val]\n",
    "\n",
    "\n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, ..., 2, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, ..., 2, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocabulary is {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    5956.000000\n",
       "mean        7.239087\n",
       "std         4.772394\n",
       "min         0.000000\n",
       "25%         4.000000\n",
       "50%         6.000000\n",
       "75%        10.000000\n",
       "max        53.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_len = [len(i) for i in x_train]\n",
    "pd.Series(rev_len).hist()\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_pad = padding_(x_train, 100)\n",
    "x_test_pad = padding_(x_test,100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5956,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,  40,  51, 682, 368, 310, 139,\n",
       "         948, 191], dtype=torch.int32),\n",
       " tensor(2, dtype=torch.int32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    871\n",
       "2    869\n",
       "3    851\n",
       "6    849\n",
       "5    844\n",
       "4    836\n",
       "0    836\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,output_size, embedding_dim, hidden_size, num_layers, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_dim, \n",
    "                            hidden_size = hidden_size, \n",
    "                            num_layers = num_layers,\n",
    "                            dropout = dropout,\n",
    "                            batch_first = True,\n",
    "                            bidirectional = True)\n",
    "        self.linear = nn.Linear(hidden_size*200, output_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        emb = self.embedding(inputs)\n",
    "        \n",
    "        h0 = torch.zeros(n_layers*2, inputs.size(0), hidden_dim).requires_grad_().to(device)\n",
    "        c0 = torch.zeros(n_layers*2, inputs.size(0), hidden_dim).requires_grad_().to(device)\n",
    "        \n",
    "        lstm_out, h = self.lstm(emb, (h0, c0))\n",
    "        \n",
    "        output = self.linear(lstm_out.reshape(lstm_out.size()[0], -1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)+1\n",
    "embedding_dim = 100\n",
    "hidden_dim = 32\n",
    "n_layers = 2\n",
    "output_size = 7\n",
    "\n",
    "model = LSTMModel(vocab_size,output_size, embedding_dim, hidden_dim, n_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss:1.861142873764038\n",
      "Epoch 1/5, Loss:1.6610369682312012\n",
      "Epoch 2/5, Loss:2.8628344535827637\n",
      "Epoch 2/5, Loss:1.2050210237503052\n",
      "Epoch 3/5, Loss:0.31064480543136597\n",
      "Epoch 3/5, Loss:1.216158390045166\n",
      "Epoch 4/5, Loss:0.5631343722343445\n",
      "Epoch 4/5, Loss:0.13528946042060852\n",
      "Epoch 5/5, Loss:0.015366964973509312\n",
      "Epoch 5/5, Loss:2.9444261599564925e-05\n"
     ]
    }
   ],
   "source": [
    "num_epochs  = 5\n",
    "\n",
    "loss_list = []\n",
    "iteration_list_train = []\n",
    "count_train = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.type(torch.LongTensor))\n",
    " \n",
    "\n",
    "            loss_list.append(loss.data) \n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            count_train += 1\n",
    "            iteration_list_train.append(count_train) \n",
    "            \n",
    "\n",
    "            if (i+1) % 2500 == 0:       \n",
    "                print('Epoch '+ str(epoch+1) +'/'+str(num_epochs) +', Loss:' + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test: 48 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "iteration_list_test = []\n",
    "count_test = 0\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, targets in valid_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += targets.size(0)                    \n",
    "    correct += (predicted == targets).sum()    \n",
    "\n",
    "    count_test += 1\n",
    "    iteration_list_test.append(count_test)  \n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    y_pred.extend(predicted.cpu())\n",
    "    y_true.extend(targets.cpu())\n",
    "    \n",
    "print('Accuracy of the network on the test: %d %%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "        word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n",
    "                         if preprocess_string(word) in vocab.keys()])\n",
    "        word_seq = np.expand_dims(word_seq,axis=0)\n",
    "        pad =  torch.from_numpy(padding_(word_seq,100))\n",
    "        inputs = pad.to(device)\n",
    "        batch_size = 1\n",
    "                \n",
    "        predict = model(inputs.to(device))\n",
    "        _, predicted = torch.max(predict.data, 1)\n",
    "\n",
    "        return(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion of the given line is: joy\n"
     ]
    }
   ],
   "source": [
    "predicted = predict_text('Have a wonderful dream.')\n",
    "\n",
    "print(\"Emotion of the given line is: \"+get_key(predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
